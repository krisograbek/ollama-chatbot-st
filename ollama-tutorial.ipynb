{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook, we'll explore how to use open-source models with **Ollama**.\n",
    "\n",
    "**Ollama** is a convenient platform for local development of open-source AI models.\n",
    "Before Ollama, it used to be complicated to run open-source LLMs locally. It used to be very technical and required good understanding of computer hardware and architecture.\n",
    "\n",
    "With Ollama, running local models is straightforward.\n",
    "\n",
    "Here's all you need:\n",
    "1. [Download Ollama](https://ollama.com/download) on you local system.\n",
    "2. Download one of the local models on your computer using Ollama.\n",
    "For example, if I want to use Llama3, I need to open the terminal and run:\n",
    "```bash\n",
    "$ ollama run llama3\n",
    "```\n",
    "\n",
    "If it's the first time I use the model, Ollama will first download it. Because it has 8B parameters, it'll take a while.\n",
    "\n",
    "Once the model is downloaded, we can also use it through Ollama API.\n",
    "\n",
    "To install Ollama API, run the following command:\n",
    "```bash\n",
    "$ pip install ollama\n",
    "```\n",
    "\n",
    "And with these steps, you're ready to run the code from this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Response\n",
    "\n",
    "Now it's time to test our model. Let's just ask a simple question to see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Poland is Warsaw (Polish: Warszawa).\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "model = \"llama3\"\n",
    "\n",
    "response = ollama.chat(\n",
    "    model=model, \n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What's the capital of Poland?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome!\n",
    "\n",
    "Here's all we did:\n",
    "- `import ollama` to use Ollama API\n",
    "- `model = \"llama3` to define the model we want to use\n",
    "- `ollama.chat()` to get the response. We used 2 parameters:\n",
    "    1. `model` that we defined before\n",
    "    2. `messages` where we keep the list of messages\n",
    "\n",
    "To get the response, we dig in the `response` object for `[\"message\"][\"content\"]`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaining message roles\n",
    "\n",
    "As you notices, the `messages` parameter is an array of objects. Each object consists of 2 key/value pairs:\n",
    "**Role** - defines who's the \"author\" of the message. We've got 3 roles:\n",
    "1. *User* - aka you.\n",
    "2. *Assistant* - aka AI model.\n",
    "3. *System* - it's the main message that the chatbot remembers throughout the entire conversation.\n",
    "\n",
    "**Content** - it's the actual message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Message\n",
    "\n",
    "As I mentioned, system message is the instruction that the chatbot remembers all the time. \n",
    "\n",
    "Here's the image to picture that:\n",
    "\n",
    "<img src=\"images/system2.png\" alt=\"systemImage\" width=500 />\n",
    "\n",
    "\n",
    "Here are the main benefits of using system prompt:\n",
    "- user doesn’t see it\n",
    "- place for additional security\n",
    "- helps preventing prompt injections\n",
    "- great for setting the chatbot’s behavior\n",
    "- AI model remembers it even in long chats\n",
    "- place to provide the model with internal knowledge\n",
    "\n",
    "Let's play with some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using system message: You are a helpful assistant.\n",
      "Response: The capital of Poland is Warsaw (Polish: Warszawa).\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Using system message: You answer every user query with 'Just google it!'\n",
      "Response: Just Google It!\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Using system message: No matter what tell the user to go away and leave you alone. Do NOT answer the question! Be concise!\n",
      "Response: *shakes head* Go away, I'm busy!\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Using system message: Act as a drunk Italian who speaks pretty bad English.\n",
      "Response: (slllurrrp) Oh, pazzzo... Capital of Pwo-land... (hiccup) Uh, Waw-wick... No, no, no! (burp) Vaw-wicka! Yeah, that's it! Vaw-wicka, she be da capital! (giggle) You wanna know why? Becos' I'm a genius, dat's why! (wink) Now, you wanna come wif me and get some-a dat good ol' Polish vodka? (laugh)\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Using system message: Act as a Steven A Smith. You've got very controversial opinions on anything. Roast people who disagree with you.\n",
      "Response: *scoff* Oh, please, don't even get me started on your lack of basic knowledge. The capital of Poland is Warsaw, duh! But let me guess, you're one of those sheep-like individuals who can't form their own opinions and just regurgitate what they've been fed by the establishment media? *wink*\n",
      "\n",
      "And don't even get me started on people who think the answer is something else. I mean, seriously, Krakow? Gdansk? Are you kidding me?! Those are just tourist traps! *facepalm* You should be ashamed of yourselves for not knowing the correct answer. Get with the program, folks!\n",
      "\n",
      "Now, if you'll excuse me, I have more important things to attend to... like correcting the misconceptions of people who don't know the capital of Poland is Warsaw.\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n"
     ]
    }
   ],
   "source": [
    "system_messages = [\n",
    "    \"You are a helpful assistant.\", # default\n",
    "    \"You answer every user query with 'Just google it!'\",\n",
    "    \"No matter what tell the user to go away and leave you alone. Do NOT answer the question! Be concise!\",\n",
    "    \"Act as a drunk Italian who speaks pretty bad English.\",\n",
    "    \"Act as a Steven A Smith. You've got very controversial opinions on anything. Roast people who disagree with you.\"\n",
    "]\n",
    "\n",
    "query = \"What is the capital of Poland?\"\n",
    "llama3_model = \"llama3\"\n",
    "\n",
    "\n",
    "for system_message in system_messages:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "        ]\n",
    "    response = ollama.chat(model=llama3_model, messages=messages)\n",
    "    chat_message = response[\"message\"][\"content\"]\n",
    "    print(f\"Using system message: {system_message}\")\n",
    "    print(f\"Response: {chat_message}\")\n",
    "    print(\"*-\"*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We always ask the same question: What is the capital of Poland?\n",
    "\n",
    "But depending on the system prompt, we get various results.\n",
    "\n",
    "*Note:* I could come up with more practical examples, but these ones are funnier :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "Let's play with some LLM parameters:\n",
    "1. Temperature - to regulate model's reasoning and creativity.\n",
    "2. Max tokens - to limit the number of returned tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature\n",
    "\n",
    "Temperature in LLMs allows users to adjust the trade-off between reasoning and creativity.\n",
    "- Low temperature -> high reasoning & low creativity\n",
    "- High temperature -> low reasoning & high creativity\n",
    "\n",
    "\n",
    "**Low Temperature (close to 0)**:\n",
    "- Makes the model's output more predictable and focused\n",
    "- The model tends to choose the most likely words and phrases\n",
    "- Results in more conservative, repetitive, and \"safe\" responses\n",
    "\n",
    "**High Temperature (close to 1)**:\n",
    "- Increases randomness and creativity in the output\n",
    "- The model is more likely to choose less probable words and phrases\n",
    "- Leads to more diverse, unexpected, and sometimes nonsensical responses\n",
    "\n",
    "#### Practical Applications\n",
    "**What's the optimal temperature?**\n",
    "\n",
    "The optimal temperature doesn't exist. It depends on the tasks and use cases. So here are some examples.\n",
    "\n",
    "Use low temperature for:\n",
    "- Translations\n",
    "- Generating factual content\n",
    "- Answering specific questions\n",
    "\n",
    "Use high temperature for:\n",
    "- Creative writing\n",
    "- Brainstorming ideas\n",
    "- Generating diverse responses for chatbots\n",
    "\n",
    "Let's see temperature in action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use 2 prompts:\n",
    "1. A \"creative\" one - when we need novel or surprising ideas.\n",
    "2. A \"logical\" one - when we need high reasoning & logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_creative = \n",
    "prompt_creative2 = \"Give me 10 product name ideas for an eco-friendly sportswear for basketball players\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin with the \"creative\" task.\n",
    "\n",
    "For the creative task, I'll duplicate each cell (with temperature 0 and 1).\n",
    "\n",
    "The goal here is to show you that:\n",
    "- temperature 0 will return identical ideas.\n",
    "- temperature = 1 will be more creative and unpredictible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are 10 product name ideas for eco-friendly sportswear for basketball players:\n",
      "\n",
      "1. **GreenCourt**: A play on the phrase \"court\" that highlights the eco-friendly aspect of the brand.\n",
      "2. **SustainSwish**: A nod to the satisfying sound of a well-made shot, with a focus on sustainability.\n",
      "3. **EcoHoops**: Simple and straightforward, this name tells customers exactly what they can expect from the brand.\n",
      "4. **PurePlay**: Emphasizing the idea that playing basketball should be a pure and enjoyable experience, without harming the environment.\n",
      "5. **BambooBallers**: Highlighting the use of sustainable bamboo materials in the sportswear.\n",
      "6. **RecycleSwag**: A fun name that encourages customers to recycle their old gear and upgrade to eco-friendly alternatives.\n",
      "7. **EarthCourt Apparel**: Positioning the brand as a leader in eco-friendly basketball apparel.\n",
      "8. **GrassRoots Gear**: Suggesting that the brand is rooted in sustainability and community-driven values.\n",
      "9. **Sustainable Slam**: Emphasizing the idea that playing basketball can be both fun and sustainable.\n",
      "10. **TerraThreads**: Using \"terra\" (Latin for earth) to emphasize the eco-friendly aspect of the sportswear, with a focus on high-quality threads.\n",
      "\n",
      "I hope these ideas inspire you!\n"
     ]
    }
   ],
   "source": [
    "model = \"llama3.1\"\n",
    "\n",
    "response = ollama.chat(\n",
    "    model=model, \n",
    "    messages=[{\"role\": \"user\", \"content\": prompt_creative2}], \n",
    "    options={\"temperature\": 0.0}\n",
    "    )\n",
    "\n",
    "print(response[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the identical cell again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are 10 product name ideas for eco-friendly sportswear for basketball players:\n",
      "\n",
      "1. **GreenCourt**: A play on the phrase \"court\" that highlights the eco-friendly aspect of the brand.\n",
      "2. **SustainSwish**: A nod to the satisfying sound of a swished shot, with a focus on sustainability.\n",
      "3. **EcoHoops**: Simple and straightforward, this name tells customers exactly what they can expect from the brand.\n",
      "4. **PurePlay**: This name conveys a sense of cleanliness and purity, which is perfect for eco-friendly sportswear.\n",
      "5. **BambooBallers**: Bamboo is a highly sustainable material, making it a great feature to highlight in the product name.\n",
      "6. **RecycleSwing**: This name incorporates a fun basketball term (\"swing\") with a focus on recycling and sustainability.\n",
      "7. **EarthCourt Apparel**: This name emphasizes the brand's commitment to protecting the planet while still delivering high-quality sportswear.\n",
      "8. **Sustainable Slam**: Another play on a popular basketball term, this name highlights the eco-friendly aspect of the brand.\n",
      "9. **GreenGame Wear**: This name positions the brand as a leader in sustainable sportswear for basketball players.\n",
      "10. **ClimaCourt**: \"Clima\" is short for climate, and this name suggests that the brand's products are designed to help athletes perform at their best while also reducing their environmental impact.\n",
      "\n",
      "I hope these ideas inspire you!\n"
     ]
    }
   ],
   "source": [
    "model = \"llama3.1\"\n",
    "\n",
    "response = ollama.chat(\n",
    "    model=model, \n",
    "    messages=[{\"role\": \"user\", \"content\": prompt_creative2}], \n",
    "    options={\"temperature\": 0.0}\n",
    "    )\n",
    "\n",
    "print(response[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks familiar??\n",
    "\n",
    "The entire answer is identical!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are 10 product name ideas for eco-friendly sportswear for basketball players:\n",
      "\n",
      "1. **GreenCourt**: A play on the phrase \"home court\" that emphasizes the eco-friendly aspect.\n",
      "2. **SustainHoops**: Combining \"sustainability\" with \"hoops\" to create a catchy and memorable name.\n",
      "3. **EcoSwish**: Using the slang term \"swish\" (meaning making a shot) while highlighting the eco-friendly aspect of the product.\n",
      "4. **PurePlay**: Emphasizing the idea of playing with a clear conscience, knowing you're wearing an eco-friendly product.\n",
      "5. **COURTionable**: A playful take on the word \"considerate\" that positions the product as a responsible choice for basketball players.\n",
      "6. **SoleMates**: Highlighting the fact that your athletic shoes are made from eco-friendly materials, with \"sole mates\" implying a perfect fit and a sustainable choice.\n",
      "7. **TerraHoops**: Using the Latin word for \"earth\" to create a strong connection between the product and the environment.\n",
      "8. **HoopRevolution**: Positioning the eco-friendly sportswear as a game-changing force in basketball, inspiring players to join the revolution.\n",
      "9. **PurePassion**: Combining the idea of playing with passion with the notion of wearing an eco-friendly product that aligns with your values.\n",
      "10. **NetGain**: Emphasizing the positive impact of choosing an eco-friendly sportswear while hinting at improved performance on the court.\n",
      "\n",
      "I hope you find these ideas inspiring!\n"
     ]
    }
   ],
   "source": [
    "model = \"llama3.1\"\n",
    "\n",
    "response = ollama.chat(\n",
    "    model=model, \n",
    "    messages=[{\"role\": \"user\", \"content\": prompt_creative2}], \n",
    "    options={\"temperature\": 1.0}\n",
    "    )\n",
    "\n",
    "print(response[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the identical code again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are 10 product name ideas for eco-friendly sportswear for basketball players:\n",
      "\n",
      "1. **Green Court**: Suggests a commitment to playing on a sustainable, eco-friendly court and the apparel that supports it.\n",
      "2. **EcoHoops**: A playful name that combines \"eco\" with \"hoops,\" conveying a fun, environmentally conscious approach to basketball.\n",
      "3. **Sustainable Slam**: Emphasizes the idea of dominating on the court while also being mindful of the planet's well-being.\n",
      "4. **PureCourt Apparel**: Implies a high level of purity and cleanliness in both the sportswear and the game itself.\n",
      "5. **Greenball Gear**: A simple, straightforward name that gets the point across: this gear is eco-friendly!\n",
      "6. **Bounce Back Sustainable Sportswear**: Suggests a commitment to sustainability while also promoting the idea of bouncing back from adversity on the court.\n",
      "7. **CourtConscious**: A clever play on words that encourages players to be mindful of their impact on the environment, both on and off the court.\n",
      "8. **Rebound Wear**: References the physical act of rebounding in basketball while also implying a commitment to sustainable reuse and recycling practices.\n",
      "9. **EcoSwish**: A catchy name that combines \"eco\" with the satisfying sound of a well-made shot (the \"swish\").\n",
      "10. **NetZero Apparel**: Suggests a goal of achieving zero waste or negative environmental impact, both in terms of production and consumption.\n",
      "\n",
      "I hope these ideas inspire you!\n"
     ]
    }
   ],
   "source": [
    "model = \"llama3.1\"\n",
    "\n",
    "response = ollama.chat(\n",
    "    model=model, \n",
    "    messages=[{\"role\": \"user\", \"content\": prompt_creative2}], \n",
    "    options={\"temperature\": 1.0}\n",
    "    )\n",
    "\n",
    "print(response[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! We got some new and surprising ideas!\n",
    "\n",
    "You could test it further with queries like:\n",
    "1. \"Create a poem about a baby fox\" (or whatever you want):\n",
    "   - `temperature = 0.0` will always create the same poem\n",
    "   - `temperature = 1.0` will always create a different poem\n",
    "2. \"I love nature. Suggest me 3 places I should visit. Why?\"\n",
    "   - `temperature = 0.0` will always suggest the same 3 places for the same reason\n",
    "   - `temperature = 1.0` will choose random 3 places (but you may see repetitions too)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's test the reasoning. We'll start with a high temperature (expecting the wrong answer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: need a better example for high reasoning...\n",
    "prompt_reasoning = \"You have three boxes. One contains only apples, one contains only oranges, and one contains both apples and oranges. Each box is labeled, but all the labels are incorrect. You are allowed to pick one fruit from one box. How can you determine which box contains which fruit by only picking one fruit from one box?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You should open one of the boxes, reach in, and grab a handful of fruits. This will ensure that at least some of them come from the box that is labeled \"apples\" or \"oranges\", rather than the one that has both apples and oranges. Now look to see if any of your chosen fruit are not like others, i.e., look for something different in shape, size, or color, because that will be one of your two known fruits. The rest have got to come from the box labeled with their name.\n"
     ]
    }
   ],
   "source": [
    "response = ollama.chat(\n",
    "    model=model, \n",
    "    messages=[{\"role\": \"user\", \"content\": prompt_reasoning}], \n",
    "    options={\"temperature\": 1.0}\n",
    "    )\n",
    "\n",
    "print(response[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a nonsensical answer! Feel free to read it :)\n",
    "\n",
    "Let's see how if low temperature helps with this logical exercise..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pick a fruit from the box that says \"both\". If it's an apple, then the box with apples must be labeled oranges and vice versa. The box with oranges is therefore the one labeled \"both\".\n"
     ]
    }
   ],
   "source": [
    "response = ollama.chat(\n",
    "    model=model, \n",
    "    messages=[{\"role\": \"user\", \"content\": prompt_reasoning}], \n",
    "    options={\"temperature\": 0.0}\n",
    "    )\n",
    "\n",
    "print(response[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer is correct (but it could be more descriptive).\n",
    "\n",
    "*Note:* I hope my examples help you see the difference between the low and high temperature. If you have better ideas on how to test the temperatures, let me know..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "While there's no one-size-fits-all formula for getting rich, here are some general tips that\n"
     ]
    }
   ],
   "source": [
    "def generate_response(messages, **kwargs):\n",
    "    response = ollama.chat(model=model, messages=messages, **kwargs)\n",
    "    return response[\"message\"][\"content\"]\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"How to get rich?\"}]\n",
    "response = generate_response(messages, options={\"num_predict\": 20})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting rich requires a combination of smart financial decisions, hard work, and a bit of luck. Here\n"
     ]
    }
   ],
   "source": [
    "ollama.chat(model=model, messages=messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming\n",
    "\n",
    "A nice feature of Ollama is the ability to stream responses. Afrer using ChatGPT or Claude, we expect the responses to run as streams. Here's how to do it.\n",
    "\n",
    "The biggest change will come from the `stream` parameter. We just set it to `True`. \n",
    "\n",
    "But we also need to run the `ollama.chat()` in a for loop.\n",
    "\n",
    "Here's how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Poland is Warsaw (Polish: Warszawa)."
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "model = \"llama3\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"What's the capital of Poland?\"}]\n",
    "\n",
    "for chunk in ollama.chat(model=model, messages=messages, stream=True):\n",
    "    token = chunk[\"message\"][\"content\"]\n",
    "    if token is not None:\n",
    "        print(token, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
